{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "\n",
    "import numpy as np\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0, 5001, size = (1000, 20))\n",
    "print(X.shape)\n",
    "\n",
    "# print the shape of X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = np.mean(X, axis = 0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = np.std(X, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2548.976 2432.224 2455.653 2465.298 2481.524 2494.22  2413.975 2436.155\n",
      " 2531.911 2461.238 2485.593 2516.234 2463.352 2454.872 2549.059 2493.754\n",
      " 2527.709 2436.425 2477.695 2488.551]\n",
      "[1449.82986154 1461.07440941 1448.45457526 1465.38676164 1473.57309063\n",
      " 1431.91796888 1436.43784424 1438.04366101 1422.18332119 1449.34888048\n",
      " 1444.79122276 1424.62660415 1426.92145898 1448.66190728 1444.20961135\n",
      " 1428.56040946 1457.33893529 1435.19761858 1417.68374822 1437.45354687]\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols)\n",
    "print(std_cols)\n",
    "\n",
    "# Print the shape of std_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X - ave_cols) / std_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of all the values of X_norm =  2.788880237858393e-17\n",
      "The average of the minimum value in each column of X_norm =  -1.7170022417626616\n",
      "The average of the maximum value in each column of X_norm =  1.7444521590193922\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(\"Average of all the values of X_norm = \", X_norm.mean())\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(\"The average of the minimum value in each column of X_norm = \", X_norm.min(axis = 0).mean())\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(\"The average of the maximum value in each column of X_norm = \", X_norm.max(axis = 0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 0, 3, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[270 539 684 201 505 908 294 187 361 782 880 798 424 397 315 578 394 920\n",
      " 100 159 207  10 941 996 802 965 441 536 177 379 837 490 374 889 850 961\n",
      " 601 640   8 745 891 279 544 689 349 940 895 649 718 143 759 631 107 404\n",
      " 286 739 733 252 890 163 485  81  51 395 948 266 421 158 519 781 751 459\n",
      " 611 788 613 775 405 962 707 752 713  57 278 945 337 184 620 592  17  28\n",
      "  87 618 269 260 562 488  72 480 657 555 477 132 437  97 805 136 249 756\n",
      " 106 623 550 242 871 276 858 546 564  80 321 290 151 500 841 742 498 128\n",
      " 228 141 382  78 510 178 726 360 801 529 522 479 130 149 450 668 567 982\n",
      " 905 763 879 427 887 682  70 793  65 724 702 582 732  96 963 385 698 420\n",
      " 990 899 414 834 375 428 731 311 124 392 893 935 624 438 238 273 204 210\n",
      " 291  31 575 507 463 966 423 764 743 799 922 717 540 484 577 502 626 816\n",
      " 944 857 205 152 791 351 688 429 525  64 319 324 747 969 892 444  54 661\n",
      " 855   0 168 308 109 105 330 524 952 345  16 807 610 528 548 326 425 368\n",
      " 516 416 472 406 285 194 840 859  21 419 434 942 591 223  47 542 497 241\n",
      " 734 823 346 126 839 418 268 259 435 561 619 902 919 521 810 261 471 554\n",
      " 520 738 881  50 901 244 150 825  52 281 386 606 648 872 353 487 875 721\n",
      " 452  15 515  76 192 697 906 413 227 482 563 609 514 103 869 411 310 929\n",
      " 675 708 673 169  12 701 292 955 409 700 804 185 363 797 730 818 455 883\n",
      " 332 636 206 995 754 886 950 654 928 605 864 272 910 118  94 501 233 355\n",
      " 440 664  85 979 245 695 439   6 749 676 543 553 874 222 658 680 191 809\n",
      " 122 535 344 277 108 229 156 617  60 317  25  77  24 571 849  74 727 264\n",
      " 216 740 253 220 320 835  59 602 401 523 627 927 534 923 199  22 632 660\n",
      " 914  40 356 506 603 584 757 147  32   2 666 430 456 964 139  41 766 117\n",
      " 262 817 843 422 300 712 593 958 590 960 836 585 833 289 464 343 980 959\n",
      " 581 101 989 389 432 131 449 685 894 263 904 309 161 339 679  45 828 790\n",
      " 217 513 780 475 845 176 813 769  68 297 102 957 447 796 795 248 312 342\n",
      "  62 687  98 446 381 243  58 706 806  48 388   3 983 830  27 744  19 579\n",
      " 777 545 622 301 347 209 538 907 313 153 493 196 580 674 924  49 137 832\n",
      " 338 376 486 451 715 236 846 255 974 186 863 643 504 104 183  26 511 473\n",
      "  95  43 709 203 274 336 465 720 938 271 181 856 526 767 167 946 635  11\n",
      " 378 219 588 630 936 173 155 341 481 211 458 986 170 417 367 725 398 467\n",
      " 847 939 531 865  34 933 656 230 663 415 140 116 978 371 971 145  33  67\n",
      " 932  29 202 681 860 532 354 460 189 703 612 175 998 644 492 693 628 470\n",
      " 240 762 231 533 157  36 652 916 737 478 442 283 461 598 226 232 221 573\n",
      " 179  42 284 753 551 954 390 426 653 583  61 224 898 113 956 842 710 350\n",
      " 808   4 466 778 399 144 331 328 642 491 408 723  84 909 111   5 587 560\n",
      " 496 133 868 316 549 267 853 383 258 123 329 333 783 814 125 547 765 984\n",
      " 758 784 172 719 696 776 903 746 164 322  89 760  79 121 306 705 366 412\n",
      " 967 683 352 359 831 900 970 160 114 678 115 639 387 867 370 690 625 792\n",
      " 146  20 303 288 913 870 595 866 997 574 873 741 494  39 589 716 667 318\n",
      " 250 148  46 180 803  69 215 915 665 921 607 953 476 112 307 691 400 994\n",
      " 129  82 934 165 608 931 246  55 614 212 556 785 495 410 340 443 369 669\n",
      " 235 629 138 977 557 298 711 848 302 596 728 499 552 819 474 930 729 662\n",
      "  71 794 565 188  37 692 254 198 457 862  83 305 182  88 348  23 876 135\n",
      " 786  38 851 670 826  86 569 517 882 407 604 616 314 877  44 512 566 827\n",
      " 373   7 508 127 509 645 600 981 197 686  35 822 773 365  99 947 812 993\n",
      " 568 634 237 704 570 503 918 299 304 256 659 992 987  93 393 239 576 852\n",
      " 257 537 380 943 193 815 770 615 761 110 208 275 558 362 119 951 789  66\n",
      " 714 265 829 586 357 888 677 327 559 372 120 949 599 975 166 364 489 483\n",
      " 844 234 358 925 671 750 771 171 633   9 154 174 854 885 296 518 912 755\n",
      " 190 736 323 213 768 462 431 926 917  91 454 391 572  14 638 821 779 621\n",
      " 896 735 999 225 445 218 878  63 824 641 142 293 453 214 200 396  13 694\n",
      " 134 976   1 377 251 646 594 195 787 469 897 811  53 162  90 884 820 647\n",
      " 334  30 672 335 468  73 282 541  18 403 937 287 748 325 247 911 637 968\n",
      " 699  75 651 973 597 985 530 295 774  92 772 384  56 527 448 655 838 722\n",
      " 436 988 650 800 991 402 280 861 972 433]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.11049168  1.61578081 -0.51064977 ... -0.40651196  0.70347495\n",
      "  -0.2369127 ]\n",
      " [ 0.34350513  0.27224897 -1.06434335 ... -1.56941802 -1.56360331\n",
      "   1.12521827]\n",
      " [-1.27047735 -1.59623903 -1.17963865 ...  1.19535803  0.98562532\n",
      "   0.57633097]\n",
      " ...\n",
      " [-1.1490838  -1.48193958  0.72238855 ...  0.31743015 -1.56571944\n",
      "   0.74120587]\n",
      " [-0.30139812  0.97789407 -0.21585282 ...  0.86160608 -1.32659699\n",
      "   1.19061169]\n",
      " [-0.30967496 -1.24581198 -1.22589485 ...  1.49009096 -0.55138884\n",
      "   0.99860549]]\n",
      "[[-1.01803394 -0.40533459  0.19078748 ...  0.86299962  0.01432266\n",
      "  -0.57640193]\n",
      " [-1.59396358  0.74450418 -0.74883467 ... -1.35829726  1.05616291\n",
      "   0.50745918]\n",
      " [ 0.07864647 -0.36769106 -0.21032969 ... -0.76256049 -1.04021437\n",
      "   1.21704733]\n",
      " ...\n",
      " [ 1.58985827 -1.15204536  0.50767695 ...  0.32997198 -0.38633087\n",
      "  -0.35169902]\n",
      " [-0.87249962 -1.15683636 -0.40985269 ... -1.46978017 -1.36327654\n",
      "  -0.24317377]\n",
      " [-1.08493834  0.36122459 -0.48441492 ... -1.64606251 -0.10347512\n",
      "   1.16695875]]\n",
      "[[ 1.5808917  -0.11855933  1.6544164  ...  1.58415466 -0.67624038\n",
      "   0.03579177]\n",
      " [ 1.66917793  0.17642907 -0.2324222  ...  1.11174585  0.05452909\n",
      "   0.81494738]\n",
      " [-1.03734655 -1.00147124  1.18978326 ... -1.27468509 -0.34471369\n",
      "  -1.58860855]\n",
      " ...\n",
      " [-0.95388848 -0.19247753  0.06030358 ... -0.85105005  0.33950096\n",
      "  -0.96319704]\n",
      " [-1.14356591 -0.26708017 -0.26763214 ... -0.52774962  0.04747533\n",
      "   0.58676609]\n",
      " [-0.98285739 -0.67431473 -0.89105521 ... -0.13128854 -0.00683862\n",
      "   0.94086449]]\n"
     ]
    }
   ],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "\n",
    "\n",
    "# Create a Training Set -> 60 % i.e. 0.6\n",
    "X_train = X_norm[row_indices[: int(len(X_norm) * 0.6)], :]\n",
    "print(X_train)\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[row_indices[int(len(X_norm) * 0.6) : int(len(X_norm) * 0.8)], :]\n",
    "print(X_crossVal)\n",
    "# Create a Test Set\n",
    "X_test = X_norm[row_indices[int(len(X_norm) * 0.8) :], :]\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n",
      "(200, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "\n",
    "print(X_train.shape)\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
